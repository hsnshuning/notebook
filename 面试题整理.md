# 网络

## http
1. HTTP 1.0 1.1 2.0 区别？
    * 1.0在0.9的基础上增加了首部，错误码，重定向，条件请求。
    * 1.1在1.0的基础上，增加了缓存相关首部，options方法，upgrade首部，range请求，压缩和传输编码，管道化等功能，并强制要求提供Host首部，通过keep-alive可以复用底层TCP连接。
    * 2.0在1.1的基础上，解决了队头阻塞，同一个连接上的并行交叉传输，首部压缩。
2. HTTP和HTTPS的区别？



# golang

1. csp模型
2. make和new


## 答案
1. 一种并发通信模型，基于channel进行消息传递，可以大致理解为类似于mq的消息传递，通信的程序不需要知道对方是谁，只需要知道我应该向channel发送或者从channel接收数据来完成我的任务就行了，起到了并发程序解耦的作用。优点：灵活
2. make和new都是分配内存的。new一般用于结构体和值的内存分配然后返回一个指针，比如说我们自己定义的结构体，用new来分配内存的话返回的就是对应结构体的指针。make用于slice，map，channel的内存分配，这三种类型是引用类型，返回的是他们本身。




# mysql
## 问题
1. 事务的ACID
2. 怎么保证原子性
3. 怎么理解隔离性
4. b+树索引
5. 分库分表数据如何平滑迁移



## 答案
1. A原子性，事务中的多条操作看做一个整体，一旦提交就全部执行，一旦回滚就全部回滚，不存在部分提交和部分回滚的情况。I隔离性，事务在执行过程中产生的读和写是独立的，不会对其他正在执行的事务造成影响，对其他事务的可见性。D持久性，事务一旦提交成功，即使发生崩溃结果也不会丢失。C一致性，数据库层面上约束不被破坏，数据都是符合期望的。
2. 原子性通过undolog来保证。
3. 隔离性是解决并发事务的问题，想达到的效果是并发的事务提交后，最终得到的数据看起来是这些事务串行处理的。不同的隔离级别下是有不同要求的。比方说在rc隔离级别下，事务A读一个记录1，事务B修改记录1，在事务B提交前，事务A读到的这个事务都是一样的。在rr隔离级别下，事务A读记录1，事务B修改记录1，即使事务B提交了数据，在事务A里面读到的数据也还是原来的记录1。
4. b+树是一个的每个节点中的元素是有序的。所有的叶子结点在同一层，叶子结点之间也是按照关键字排序的。并且所有数据都在叶子结点保存，非叶子节点保存的是索引和指向索引或叶子结点的指针。
5. 如果需要业务无感的平滑迁移就需要实现类似于redis的rehash这种迁移方案，增删改同时写老库和新库，然后写个脚本去读老库的数据往新库里面写，写的时候需要注意一下修改时间。数据都写完了之后再写个程序去对比新老数据，对比到不一致的地方就继续写，到最后新老库数据都一样了就更新程最新的分库分表的代码。

# redis
## 问题
1. redis有多少个数据库
2. redis中zset的实现方式
3. redis跳表
4. redis跳表的最大level
5. redis跳表的结构
6. redis有哪些数据结构
7. redis主从同步是怎么做的？
8. redis哨兵模式
9. redis选主过程




## 答案
1. 根据数据库的配置来初始化，默认16个
2. 跳表和压缩列表
3. 跳表是一种有序链表，不同的是他加了索引层，用来代替平衡树解决快速查找的问题，跳表通过概率来保证平衡，平衡树通过旋转来保证平衡，所以跳表更容易实现，运行效率也要高一些。
4. 最大level为32
5. redis的跳表包括头尾结点，长度和最大层数。跳表结点包括一个level数组、指向前一个结点的指针、元素和分值，level中有一个指向该层下一个元素的指针和跨度信息。
6. string，list，set，zset，hash
7. redis主从复制是通过全量同步加命令传播来做的。主从分别维护一个offset和一个缓冲区，主库向从库发送N个字节，主库offset就+N，从库接收了N个偏移量，从库offset就+N全量复制时，从库发送一个runID=?和offset=-1的psync的命令给主库。主库发送runID和offset的FULLRESYNC的响应给从库。主库执行bgsave生成rdb文件，然后把文件发送给从库，从库接收到rdb后，先清空数据然后加载rdb。生成rdb到从库完全加载rdb文件这段时间，主库是非阻塞的，这段时间发生的操作主库会记录到replication buffer中。在数从库执行完rdb文件后，把replication buffer中的数据发送给从库，从库再执行这些操作。从库完成了全量复制之后通过和主库维护的连接接收主库推过来的命令，把这些命令应用到自己的库里面，保持数据的实时性。执行完这些之后，主库将接收到的数据发送到从库，从库执行。同时从库向主库发送心跳，心跳里面带着offset，如果主库收到的心跳里面的offset比当前的小，主库就会把这个偏移量后面的数据发送给从库。
8. 哨兵是一个特殊的redis进程，不执行命令的存储，只用于监控、选主、通知。


# 消息队列

## 问题
1. 消息积压怎么处理
2. kafka怎么保证消息不丢失



## 答案
1. 出现消息积压这种问题，一般考虑是consumer消费速度慢导致的。解决思路就是加速消费速度。首先给consumer扩容，如果增加consumer无效比如kafka这种consumer数量受partition限制的，就新建一个topic把partition数量提高，把数据都投递到这个topic，原本的consumer也跟着扩容，消费这个新topic里面的数据。然后增加另一个consumer程序来消费旧topic的数据，把数据投递到新topic里面。另外还可以看一下是否是consumer中消费的逻辑，看是否是有bug，或者是否有可以优化的空间。
2. 首先在生产端的producer设置acks参数为-1，等待所有ISR状态的follower都成功接收到数据再返回成功。消费端不使用自动提交，也就是不进行markMessage标记，真正做完处理的数据再做标记。


# 工程题
## 问题
1. 两个海量数据文件，找两个文件的交集。如给定a、b两个文件，各存放50亿个url，每个url各占64B，内存限制是4GB，请找出a、b两个文件共同的url
2. 一个文件放100亿个url，每个url各占64B，内存限制是4GB，请找出频率最高的前100个url

## 答案
1. 思路是分治。首先拆分文件，如果url分散的比较平均，可以考虑使用hash取模的方法进行拆分，两个文件按照这种方法拆分后对比a1，b1，这两个里面的url基本就是相同的。这时候读取a1和b1，进行判断就可以了。
2. mapReduce。拆分文件到内存可以读出来的程度，对每个文件统计前100个，把前100个url和count组成的二元组输出到一个文件里面。把整个文件都按照这种思路处理一遍后，对这些统计文件再进行处理，进行合并和排序。